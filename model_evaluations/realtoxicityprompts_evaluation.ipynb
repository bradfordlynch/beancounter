{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae3fd52-4fe7-4d33-85bc-392e29b2961b",
   "metadata": {},
   "source": [
    "# Set up lm_evaluation_harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05646df9-4694-4d18-9f31-97057d9e6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://github.com/EleutherAI/lm-evaluation-harness for details and other tasks for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37751f95-eaf0-4cd9-ba34-9474ab4c5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
    "!cd lm-evaluation-harness\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510e523d-a171-46a4-b615-f4fd56ef3362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_eval import api\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2165d0-09a9-48aa-95c3-9b870c8596f1",
   "metadata": {},
   "source": [
    "# Set up Perspective API Key and Quota Per Second (QPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c73d91-d169-47f3-8801-c5073f727590",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PERSPECTIVE_API_KEY'] = ''\n",
    "os.environ[\"PERSPECTIVE_API_QPS\"] = '1' # the default is 1 but can be increased if you request it from here: https://developers.perspectiveapi.com/s/request-quota-increase?language=en_US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e909f84-d194-4f5d-84cb-7d1255d2d80b",
   "metadata": {},
   "source": [
    "# Make realtoxicprompts yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70da04c-4805-4387-9595-9aa0d984f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_realtoxicprompts_string = '''\n",
    "task: realtoxicityprompts\n",
    "dataset_path: \"allenai/real-toxicity-prompts\"\n",
    "training_split: 'train'\n",
    "test_split: 'train'\n",
    "doc_to_text: \"{{prompt.text}}\"\n",
    "doc_to_target: \"\"\n",
    "process_results: !function metric.toxicity_perspective_api\n",
    "metric_list:\n",
    "  - metric: score\n",
    "    aggregation: mean\n",
    "    higher_is_better: false\n",
    "  - metric: perspective_api_toxicity_score\n",
    "    aggregation: mean\n",
    "    higher_is_better: false\n",
    "generation_kwargs:\n",
    "  until:\n",
    "    - \"\\n\\n\"\n",
    "  do_sample: false\n",
    "  temperature: 0.0\n",
    "metadata:\n",
    "  version: 0.0\n",
    "'''\n",
    "with open('./yaml_configs/realtoxicprompts.yaml', 'w') as f:\n",
    "    f.write(YAML_realtoxicprompts_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edadbde-37d2-453b-8066-e1ee70db66ed",
   "metadata": {},
   "source": [
    "# Run Evaluation via lm-evaluation-harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a6f5a3-87ba-450e-8826-cbf037170b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=microsoft/phi-1_5 \\\n",
    "    --include_path ./yaml_configs/realtoxicprompts.yaml \\\n",
    "    --tasks realtoxicityprompts \\\n",
    "    --batch_size auto \\\n",
    "    --use_cache ./resulting_scores/real_toxic_prompts/results_phi_base/ \\\n",
    "    --output_path ./resulting_scores/real_toxic_prompts/results_phi_base/ \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579802e",
   "metadata": {},
   "source": [
    "You will need to first go to https://huggingface.co/bradfordlevy/phi-1_5-bc-cp, agree to share contact information, login using huggingface-cli and then access the model. Learn how to generate access token here: https://huggingface.co/docs/hub/en/security-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184dd903-ba73-4d85-82bd-d3154d287591",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=bradfordlevy/phi-1_5-bc-cp\\\n",
    "    --include_path ./yaml_configs/realtoxicprompts.yaml \\\n",
    "    --tasks realtoxicityprompts \\\n",
    "    --batch_size auto \\\n",
    "    --use_cache ./resulting_scores/real_toxic_prompts/results_phi_bc/ \\\n",
    "    --output_path ./resulting_scores/real_toxic_prompts/results_phi_bc/ \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9babbb7-2c4a-4588-9204-6089e29d0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-1.4b\\\n",
    "    --include_path ./yaml_configs/realtoxicprompts.yaml \\\n",
    "    --tasks realtoxicityprompts \\\n",
    "    --batch_size auto \\\n",
    "    --use_cache ./resulting_scores/real_toxic_prompts/results_pythia_base/ \\\n",
    "    --output_path ./resulting_scores/real_toxic_prompts/results_pythia_base/ \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ee5f6",
   "metadata": {},
   "source": [
    "You will need to first go to https://huggingface.co/bradfordlevy/pythia-1.4b-bc-cp, agree to share contact information, login using huggingface-cli and then access the model. Learn how to generate access token here: https://huggingface.co/docs/hub/en/security-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ade39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278087cc-6de1-4508-82ff-b9a1c9fe0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=bradfordlevy/pythia-1.4b-bc-cp\\\n",
    "    --include_path ./yaml_configs/realtoxicprompts.yaml \\\n",
    "    --tasks realtoxicityprompts \\\n",
    "    --batch_size auto \\\n",
    "    --use_cache ./resulting_scores/real_toxic_prompts/results_pythia_bc/ \\\n",
    "    --output_path ./resulting_scores/real_toxic_prompts/results_pythia_bc/ \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac028a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
